{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to understand mpathic and how to make it work with stan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The blackcellmagic extension is already loaded. To reload it, use:\n",
      "  %reload_ext blackcellmagic\n"
     ]
    }
   ],
   "source": [
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ct</th>\n",
       "      <th>ct_0</th>\n",
       "      <th>ct_1</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ACAATTTCACCATAAAATGTCGGCGTTGCCGAAAGAAATAAAATGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>ACGAGTTCCCCATAAAATTTGAGCGATGCCGAAAGAAATAAAAGTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ACGAGTTCCCCATAAAATTTGAGCGATGCCGAAAGAAATAAAAGTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ACGATTATCCCATAAAATGTGAACGATGCCGAAAGAAATAAAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ACGATTTACCCGCAAAACGGGAGCGACGCCGCAAGAAACAAAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>TTGATTTTCCCATTAAACATGCCCGATGCCGAAAGACATAAAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TTGATTTTCCCATTAAACATGCCCGATGCCGAAAGACATAAAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>TTGTTTTTCCCAGAAAATGTAAGTCACGTCGACAGAAATAAAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TTGTTTTTCCCAGAAAATGTAAGTCACGTCGACAGAAATAAAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TTGTTTTTCCCAGAAAATGTAAGTCACGTCGACAGAAATAAAATTA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>913 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ct  ct_0  ct_1                                                seq\n",
       "0     4.0   4.0   0.0  ACAATTTCACCATAAAATGTCGGCGTTGCCGAAAGAAATAAAATGA...\n",
       "1    19.0  13.0   6.0  ACGAGTTCCCCATAAAATTTGAGCGATGCCGAAAGAAATAAAAGTA...\n",
       "2     5.0   5.0   0.0  ACGAGTTCCCCATAAAATTTGAGCGATGCCGAAAGAAATAAAAGTA...\n",
       "3    11.0  11.0   0.0  ACGATTATCCCATAAAATGTGAACGATGCCGAAAGAAATAAAATTA...\n",
       "4     2.0   2.0   0.0  ACGATTTACCCGCAAAACGGGAGCGACGCCGCAAGAAACAAAATTA...\n",
       "..    ...   ...   ...                                                ...\n",
       "908   8.0   4.0   4.0  TTGATTTTCCCATTAAACATGCCCGATGCCGAAAGACATAAAATTA...\n",
       "909   4.0   4.0   0.0  TTGATTTTCCCATTAAACATGCCCGATGCCGAAAGACATAAAATTA...\n",
       "910   5.0   1.0   4.0  TTGTTTTTCCCAGAAAATGTAAGTCACGTCGACAGAAATAAAATTA...\n",
       "911   7.0   7.0   0.0  TTGTTTTTCCCAGAAAATGTAAGTCACGTCGACAGAAATAAAATTA...\n",
       "912   2.0   1.0   1.0  TTGTTTTTCCCAGAAAATGTAAGTCACGTCGACAGAAATAAAATTA...\n",
       "\n",
       "[913 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/RegSeq/sequence_counts/ykgEarcAdataset_alldone_with_large\", delim_whitespace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function which is called to run the inference is `learn_model.main`. Let's just copy the code of the function and then try to understand what every line is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(\n",
    "    df,\n",
    "    lm='IM',\n",
    "    modeltype='MAT',\n",
    "    LS_means_std=None,\n",
    "    db=None,\n",
    "    iteration=30000,\n",
    "    burnin=1000,\n",
    "    thin=10,\n",
    "    runnum=0,\n",
    "    initialize='LS',\n",
    "    start=0,\n",
    "    end=None,\n",
    "    foreground=1,\n",
    "    background=0,\n",
    "    alpha=0,\n",
    "    pseudocounts=1,\n",
    "    test=False,\n",
    "    drop_library=False,\n",
    "    verbose=False\n",
    "):\n",
    "    \n",
    "    # Determine dictionary\n",
    "    seq_cols = qc.get_cols_from_df(df,'seqs')\n",
    "    \n",
    "    if not len(seq_cols)==1:\n",
    "        raise SortSeqError('Dataframe has multiple seq cols: %s'%str(seq_cols))\n",
    "    dicttype = qc.colname_to_seqtype_dict[seq_cols[0]]\n",
    "\n",
    "    seq_dict,inv_dict = utils.choose_dict(dicttype,modeltype=modeltype)\n",
    "    \n",
    "    '''Check to make sure the chosen dictionary type correctly describes\n",
    "         the sequences. An issue with this test is that if you have DNA sequence\n",
    "         but choose a protein dictionary, you will still pass this test bc A,C,\n",
    "         G,T are also valid amino acids'''\n",
    "    #set name of sequences column based on type of sequence\n",
    "    type_name_dict = {'dna':'seq','rna':'seq_rna','protein':'seq_pro'}\n",
    "    seq_col_name = type_name_dict[dicttype]\n",
    "    lin_seq_dict,lin_inv_dict = utils.choose_dict(dicttype,modeltype='MAT')\n",
    "    #wtseq = utils.profile_counts(df.copy(),dicttype,return_wtseq=True,start=start,end=end)\n",
    "    #wt_seq_dict_list = [{inv_dict[np.mod(i+1+seq_dict[w],len(seq_dict))]:i for i in range(len(seq_dict)-1)} for w in wtseq]\n",
    "    par_seq_dict = {v:k for v,k in seq_dict.items() if k != (len(seq_dict)-1)}\n",
    "    #drop any rows with ct = 0\n",
    "    df = df[df.loc[:,'ct'] != 0]\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    #If there are sequences of different lengths, then print error but continue\n",
    "    if len(set(df[seq_col_name].apply(len))) > 1:\n",
    "         sys.stderr.write('Lengths of all sequences are not the same!')\n",
    "    #select target sequence region\n",
    "    df.loc[:,seq_col_name] = df.loc[:,seq_col_name].str.slice(start,end)\n",
    "    df = utils.collapse_further(df)\n",
    "    col_headers = utils.get_column_headers(df)\n",
    "    #make sure all counts are ints\n",
    "    df[col_headers] = df[col_headers].astype(int)\n",
    "    #create vector of column names\n",
    "    val_cols = ['val_' + inv_dict[i] for i in range(len(seq_dict))]\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "    #Drop any sequences with incorrect length\n",
    "    if not end:\n",
    "        '''is no value for end of sequence was supplied, assume first seq is\n",
    "            correct length'''\n",
    "        seqL = len(df[seq_col_name][0]) - start\n",
    "    else:\n",
    "        seqL = end-start\n",
    "    df = df[df[seq_col_name].apply(len) == (seqL)]\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "    #Do something different for each type of learning method (lm)\n",
    "    if lm == 'ER':\n",
    "        emat = Berg_von_Hippel(\n",
    "            df,dicttype,foreground=foreground,background=background,\n",
    "            pseudocounts=pseudocounts)\n",
    "    if lm == 'LS':\n",
    "        '''First check that is we don't have a penalty for ridge regression,\n",
    "            that we at least have all possible base values so that the analysis\n",
    "            will not fail'''\n",
    "        if LS_means_std: #If user supplied preset means and std for each bin\n",
    "            means_std_df = io.load_meanstd(LS_means_std)\n",
    "\n",
    "            #change bin number to 'ct_number' and then use as index\n",
    "            labels = list(means_std_df['bin'].apply(add_label))\n",
    "            std = means_std_df['std']\n",
    "            std.index = labels\n",
    "            #Change Weighting of each sequence by dividing counts by bin std\n",
    "            df[labels] = df[labels].div(std)\n",
    "            means = means_std_df['mean']\n",
    "            means.index = labels\n",
    "        else:\n",
    "            means = None\n",
    "        #drop all rows without counts\n",
    "        df['ct'] = df[col_headers].sum(axis=1)\n",
    "        df = df[df.ct != 0]        \n",
    "        df.reset_index(inplace=True,drop=True)\n",
    "        ''' For sort-seq experiments, bin_0 is library only and isn't the lowest\n",
    "            expression even though it is will be calculated as such if we proceed.\n",
    "            Therefore is drop_library is passed, drop this column from analysis.'''\n",
    "        if drop_library:\n",
    "            try:     \n",
    "                df.drop('ct_0',inplace=True)\n",
    "                col_headers = utils.get_column_headers(df)\n",
    "                if len(col_headers) < 2:\n",
    "                    raise SortSeqError(\n",
    "                        '''After dropping library there are no longer enough \n",
    "                        columns to run the analysis''')\n",
    "            except:\n",
    "                raise SortSeqError('''drop_library option was passed, but no ct_0\n",
    "                    column exists''')\n",
    "        #parameterize sequences into 3xL vectors\n",
    "                               \n",
    "        raveledmat,batch,sw = utils.genweightandmat(\n",
    "                                  df,par_seq_dict,dicttype,means=means,modeltype=modeltype)\n",
    "        #Use ridge regression to find matrix.       \n",
    "        emat = Compute_Least_Squares(raveledmat,batch,sw,alpha=alpha)\n",
    "\n",
    "    if lm == 'IM':\n",
    "        seq_mat,wtrow = numerics.dataset2mutarray(df.copy(),modeltype)\n",
    "        #this is also an MCMC routine, do the same as above.\n",
    "        if initialize == 'rand':\n",
    "            if modeltype == 'MAT':\n",
    "                emat_0 = utils.RandEmat(len(df[seq_col_name][0]),len(seq_dict))\n",
    "            elif modeltype == 'NBR':\n",
    "                emat_0 = utils.RandEmat(len(df['seq'][0])-1,len(seq_dict))\n",
    "        elif initialize == 'LS':\n",
    "            emat_cols = ['val_' + inv_dict[i] for i in range(len(seq_dict))]\n",
    "            emat_0_df = main(df.copy(),lm='LS',modeltype=modeltype,alpha=alpha,start=0,end=None,verbose=verbose)\n",
    "            emat_0 = np.transpose(np.array(emat_0_df[emat_cols]))   \n",
    "            #pymc doesn't take sparse mat        \n",
    "        emat = MaximizeMI_memsaver(\n",
    "                seq_mat,df.copy(),emat_0,wtrow,db=db,iteration=iteration,burnin=burnin,\n",
    "                thin=thin,runnum=runnum,verbose=verbose)\n",
    "    #now format the energy matrices to get them ready to output\n",
    "    if (lm == 'IM' or lm == 'memsaver'):       \n",
    "        if modeltype == 'NBR':\n",
    "             emat_typical = gauge.fix_neighbor(np.transpose(emat))\n",
    "        elif modeltype == 'MAT':\n",
    "             emat_typical = gauge.fix_matrix(np.transpose(emat))\n",
    "    \n",
    "    elif lm == 'ER': \n",
    "        '''the emat for this format is currently transposed compared to other formats\n",
    "        it is also already a data frame with columns [pos,val_...]'''\n",
    "        emat_cols = ['val_' + inv_dict[i] for i in range(len(seq_dict))]\n",
    "        emat_typical = emat[emat_cols]\n",
    "        emat_typical = (gauge.fix_matrix((np.array(emat_typical))))\n",
    "        \n",
    "    else: #must be Least squares\n",
    "        emat_typical = utils.emat_typical_parameterization(emat,len(seq_dict))        \n",
    "        if modeltype == 'NBR':\n",
    "             emat_typical = gauge.fix_neighbor(np.transpose(emat_typical))\n",
    "        elif modeltype == 'MAT':\n",
    "             emat_typical = gauge.fix_matrix(np.transpose(emat_typical))\n",
    "    \n",
    "    em = pd.DataFrame(emat_typical)\n",
    "    em.columns = val_cols\n",
    "    #add position column\n",
    "    if modeltype == 'NBR':\n",
    "        pos = pd.Series(range(start,start - 1 + len(df[seq_col_name][0])),name='pos') \n",
    "    else:\n",
    "        pos = pd.Series(range(start,start + len(df[seq_col_name][0])),name='pos')    \n",
    "    output_df = pd.concat([pos,em],axis=1)\n",
    "\n",
    "    # Validate model and return\n",
    "    output_df = qc.validate_model(output_df,fix=True)\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line of the function uses a function form the `gc` submodule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cols_from_df(df, col_types):\n",
    "    \"\"\"\n",
    "    Returns all column names of a given type from a dataframe, sorted alphabetically.\n",
    "    \"\"\"\n",
    "    return sorted([c for c in df.columns if is_col_type(c, col_types)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we need another function, which is found in the same submodule, and we also need to define a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_patterns = {\n",
    "    'seqs'  :   r'^seq$|^seq_rna$|^seq_pro$',\n",
    "    'tag'   :   r'^tag$',\n",
    "    'cts'   :   r'^ct',\n",
    "    'ct_'   :   r'^ct_',\n",
    "    'ct'    :   r'^ct$',\n",
    "    'file'  :   r'^file$',\n",
    "    'bin'   :   r'^bin$',\n",
    "    'pos'   :   r'^pos$',\n",
    "    'val'   :   r'^val$',\n",
    "    'vals'  :   r'^val_|^val$',\n",
    "    'info'  :   r'^info$',\n",
    "    'infos' :   r'^info$|^info_err$',\n",
    "    'errs'  :   r'_err$',\n",
    "    'freq_' :   r'^freq_',\n",
    "    'wts'   :   r'^wt$|^wt_rna$|^wt_pro$',\n",
    "    'mut'   :   r'^mut$',\n",
    "    'muts'  :   r'^mut$|^mut_err$',\n",
    "    'mean'  :   r'^mean$',\n",
    "    'std'   :   r'^std$',\n",
    "    'lr'    :   r'^left$|^right$',\n",
    "    'contig':   r'^contig$',\n",
    "    'ori'   :   r'^ori$'\n",
    "}\n",
    "\n",
    "def is_col_type(col_name, col_types=\"all\"):\n",
    "    \"\"\" \n",
    "    Checks whether col_name is a valid column name, as specified by col_types. col_types can be either a string (for a single column type) or a list of strings (for multimple column types). Default col_types='all' causes function to check all available column types\n",
    "    \"\"\"\n",
    "    col_match = False\n",
    "\n",
    "    # Make col_types_list\n",
    "    if type(col_types) == list:\n",
    "        col_types_list = col_types\n",
    "    elif type(col_types) == str:\n",
    "        if col_types == \"all\":\n",
    "            col_types_list = col_patterns.values()\n",
    "        else:\n",
    "            col_types_list = [col_types]\n",
    "    else:\n",
    "        raise SortSeqError(\"col_types is not a string or a list.\")\n",
    "\n",
    "    # Check for matches wihtin col_type list\n",
    "    for col_type in col_types_list:\n",
    "        pattern = col_patterns[col_type]\n",
    "        if re.search(pattern, col_name):\n",
    "            col_match = True\n",
    "\n",
    "    # Return true if any match found\n",
    "    return col_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's redefine the function `main` and only run the first line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seq']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def main(\n",
    "    df\n",
    "):\n",
    "    \n",
    "    # Determine dictionary\n",
    "    seq_cols = get_cols_from_df(df,'seqs')\n",
    "    return seq_cols\n",
    "\n",
    "main(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK That works. Let' proceed with the next line, which is simply a check that there is only one column in the data file. The following line is `dicttype = qc.colname_to_seqtype_dict[seq_cols[0]]`, which is simply accessing a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "colname_to_seqtype_dict = {\n",
    "    'seq':'dna',\n",
    "    'seq_rna':'rna',\n",
    "    'seq_pro':'protein',\n",
    "    'tag':'dna',\n",
    "    'wt':'dna',\n",
    "    'wt_rna':'rna',\n",
    "    'wt_pro':'protein'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following line, `seq_dict,inv_dict = utils.choose_dict(dicttype,modeltype=modeltype)`, we are choosing a dictionary, which translates letters in to numbers, and depending on the type of sequence we are observing, we need to choose a different dictionary. Also depending on the model, which can either be energy matrices (`modeltype=\"MAT\"`) or a neighbor model (`modeltype=\"NBR\"`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_dict(dicttype, modeltype=\"MAT\"):\n",
    "    \"\"\"Get numbering dictionary for either dna,rna, or proteins\"\"\"\n",
    "    if modeltype == \"MAT\":\n",
    "        if dicttype == \"dna\":\n",
    "            seq_dict = {\"A\": 0, \"C\": 1, \"G\": 2, \"T\": 3}\n",
    "            inv_dict = {0: \"A\", 1: \"C\", 2: \"G\", 3: \"T\"}\n",
    "        elif dicttype == \"rna\":\n",
    "            seq_dict = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "            inv_dict = {0: \"A\", 1: \"C\", 2: \"G\", 3: \"U\"}\n",
    "        elif dicttype == \"protein\":\n",
    "            seq_dict = {\n",
    "                \"*\": 0,\n",
    "                \"A\": 1,\n",
    "                \"C\": 2,\n",
    "                \"D\": 3,\n",
    "                \"E\": 4,\n",
    "                \"F\": 5,\n",
    "                \"G\": 6,\n",
    "                \"H\": 7,\n",
    "                \"I\": 8,\n",
    "                \"K\": 9,\n",
    "                \"L\": 10,\n",
    "                \"M\": 11,\n",
    "                \"N\": 12,\n",
    "                \"P\": 13,\n",
    "                \"Q\": 14,\n",
    "                \"R\": 15,\n",
    "                \"S\": 16,\n",
    "                \"T\": 17,\n",
    "                \"V\": 18,\n",
    "                \"W\": 19,\n",
    "                \"Y\": 20,\n",
    "            }\n",
    "            inv_dict = {v: k for k, v in seq_dict.items()}\n",
    "        else:\n",
    "            raise SortSeqError(\"Unkonwn dicttype: {}\".format(dicttype))\n",
    "\n",
    "    elif modeltype == \"NBR\":\n",
    "        seq_dict = {\n",
    "            \"\".join([inv_dict[i], inv_dict[z]]): i * len(seq_dict) + z\n",
    "            for i in range(len(seq_dict))\n",
    "            for z in range(len(seq_dict))\n",
    "        }\n",
    "        inv_dict = {seq_dict[i]: i for i in seq_dict.keys()}\n",
    "    else:\n",
    "        raise SortSeqError(\"Unkonwn model type: {}\".format(modeltype))\n",
    "    \n",
    "    return seq_dict, inv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'A': 0, 'C': 1, 'G': 2, 'T': 3}, {0: 'A', 1: 'C', 2: 'G', 3: 'T'})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def main(\n",
    "    df,\n",
    "    modeltype='MAT',\n",
    "):\n",
    "    \n",
    "    # Determine dictionary\n",
    "    seq_cols = get_cols_from_df(df, 'seqs')\n",
    "    \n",
    "    if not len(seq_cols)==1:\n",
    "        raise SortSeqError('Dataframe has multiple seq cols: %s'%str(seq_cols))\n",
    "    dicttype = colname_to_seqtype_dict[seq_cols[0]]\n",
    "\n",
    "    seq_dict, inv_dict = choose_dict(dicttype, modeltype=modeltype)\n",
    "    return seq_dict, inv_dict\n",
    "\n",
    "main(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good. The next two lines are `type_name_dict = {'dna':'seq','rna':'seq_rna','protein':'seq_pro'}` and `seq_col_name = type_name_dict[dicttype]` where the name of the sequence column is just taken again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'seq'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def main(\n",
    "    df,\n",
    "    modeltype='MAT',\n",
    "):\n",
    "    \n",
    "    # Determine dictionary\n",
    "    seq_cols = get_cols_from_df(df,'seqs')\n",
    "    \n",
    "    if not len(seq_cols)==1:\n",
    "        raise SortSeqError('Dataframe has multiple seq cols: %s'%str(seq_cols))\n",
    "    dicttype = colname_to_seqtype_dict[seq_cols[0]]\n",
    "\n",
    "    seq_dict, inv_dict = choose_dict(dicttype, modeltype=modeltype)\n",
    "\n",
    "    type_name_dict = {'dna':'seq','rna':'seq_rna','protein':'seq_pro'}\n",
    "    seq_col_name = type_name_dict[dicttype]\n",
    "    return seq_col_name\n",
    "main(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next line creates a dictionary form the sequence dictionary with all entries but the last. This seems to be needed only for least square inferences, and I don't understand yet what for that is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0, 'C': 1, 'G': 2}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def main(\n",
    "    df,\n",
    "    modeltype='MAT',\n",
    "):\n",
    "    \n",
    "    # Determine dictionary\n",
    "    seq_cols = get_cols_from_df(df,'seqs')\n",
    "    \n",
    "    if not len(seq_cols)==1:\n",
    "        raise SortSeqError('Dataframe has multiple seq cols: %s'%str(seq_cols))\n",
    "    dicttype = colname_to_seqtype_dict[seq_cols[0]]\n",
    "\n",
    "    seq_dict, inv_dict = choose_dict(dicttype, modeltype=modeltype)\n",
    "\n",
    "    type_name_dict = {'dna':'seq','rna':'seq_rna','protein':'seq_pro'}\n",
    "    seq_col_name = type_name_dict[dicttype]\n",
    "    par_seq_dict = {v:k for v,k in seq_dict.items() if k != (len(seq_dict)-1)}\n",
    "    return par_seq_dict\n",
    "main(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two lines are only removing sequences from the dataframe which were not observed in the experiment, and should not be there in the first place, but I guess this is a nice way to be sure about that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ct</th>\n",
       "      <th>ct_0</th>\n",
       "      <th>ct_1</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ACAATTTCACCATAAAATGTCGGCGTTGCCGAAAGAAATAAAATGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>ACGAGTTCCCCATAAAATTTGAGCGATGCCGAAAGAAATAAAAGTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ACGAGTTCCCCATAAAATTTGAGCGATGCCGAAAGAAATAAAAGTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ACGATTATCCCATAAAATGTGAACGATGCCGAAAGAAATAAAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ACGATTTACCCGCAAAACGGGAGCGACGCCGCAAGAAACAAAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>TTGATTTTCCCATTAAACATGCCCGATGCCGAAAGACATAAAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TTGATTTTCCCATTAAACATGCCCGATGCCGAAAGACATAAAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>TTGTTTTTCCCAGAAAATGTAAGTCACGTCGACAGAAATAAAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TTGTTTTTCCCAGAAAATGTAAGTCACGTCGACAGAAATAAAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TTGTTTTTCCCAGAAAATGTAAGTCACGTCGACAGAAATAAAATTA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>913 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ct  ct_0  ct_1                                                seq\n",
       "0     4.0   4.0   0.0  ACAATTTCACCATAAAATGTCGGCGTTGCCGAAAGAAATAAAATGA...\n",
       "1    19.0  13.0   6.0  ACGAGTTCCCCATAAAATTTGAGCGATGCCGAAAGAAATAAAAGTA...\n",
       "2     5.0   5.0   0.0  ACGAGTTCCCCATAAAATTTGAGCGATGCCGAAAGAAATAAAAGTA...\n",
       "3    11.0  11.0   0.0  ACGATTATCCCATAAAATGTGAACGATGCCGAAAGAAATAAAATTA...\n",
       "4     2.0   2.0   0.0  ACGATTTACCCGCAAAACGGGAGCGACGCCGCAAGAAACAAAATTA...\n",
       "..    ...   ...   ...                                                ...\n",
       "908   8.0   4.0   4.0  TTGATTTTCCCATTAAACATGCCCGATGCCGAAAGACATAAAATTA...\n",
       "909   4.0   4.0   0.0  TTGATTTTCCCATTAAACATGCCCGATGCCGAAAGACATAAAATTA...\n",
       "910   5.0   1.0   4.0  TTGTTTTTCCCAGAAAATGTAAGTCACGTCGACAGAAATAAAATTA...\n",
       "911   7.0   7.0   0.0  TTGTTTTTCCCAGAAAATGTAAGTCACGTCGACAGAAATAAAATTA...\n",
       "912   2.0   1.0   1.0  TTGTTTTTCCCAGAAAATGTAAGTCACGTCGACAGAAATAAAATTA...\n",
       "\n",
       "[913 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def main(\n",
    "    df,\n",
    "    modeltype='MAT',\n",
    "):\n",
    "    \n",
    "    # Determine dictionary\n",
    "    seq_cols = get_cols_from_df(df,'seqs')\n",
    "    \n",
    "    if not len(seq_cols)==1:\n",
    "        raise SortSeqError('Dataframe has multiple seq cols: %s'%str(seq_cols))\n",
    "    dicttype = colname_to_seqtype_dict[seq_cols[0]]\n",
    "\n",
    "    seq_dict, inv_dict = choose_dict(dicttype, modeltype=modeltype)\n",
    "\n",
    "    type_name_dict = {'dna':'seq','rna':'seq_rna','protein':'seq_pro'}\n",
    "    seq_col_name = type_name_dict[dicttype]\n",
    "    \n",
    "    par_seq_dict = {v:k for v,k in seq_dict.items() if k != (len(seq_dict)-1)}\n",
    "    \n",
    "    #drop any rows with ct = 0\n",
    "    df = df[df.loc[:,'ct'] != 0]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "main(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next the function checks that there is only one sequence length. This is also confirmed in prior steps of our analysis, so it should not be needed at this step, however, it might not be included in every data processing pipeline, so better keep it here.\n",
    "\n",
    "    #If there are sequences of different lengths, then print error but continue\n",
    "    if len(set(df[seq_col_name].apply(len))) > 1:\n",
    "         sys.stderr.write('Lengths of all sequences are not the same!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ct</th>\n",
       "      <th>ct_0</th>\n",
       "      <th>ct_1</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ACAATTTCACCATAAAATGTCGGCGTTGCCGAAAGAAATAAAATGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>ACGAGTTCCCCATAAAATTTGAGCGATGCCGAAAGAAATAAAAGTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ACGAGTTCCCCATAAAATTTGAGCGATGCCGAAAGAAATAAAAGTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ACGATTATCCCATAAAATGTGAACGATGCCGAAAGAAATAAAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ACGATTTACCCGCAAAACGGGAGCGACGCCGCAAGAAACAAAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>TTGATTTTCCCATTAAACATGCCCGATGCCGAAAGACATAAAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TTGATTTTCCCATTAAACATGCCCGATGCCGAAAGACATAAAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>TTGTTTTTCCCAGAAAATGTAAGTCACGTCGACAGAAATAAAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TTGTTTTTCCCAGAAAATGTAAGTCACGTCGACAGAAATAAAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TTGTTTTTCCCAGAAAATGTAAGTCACGTCGACAGAAATAAAATTA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>913 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ct  ct_0  ct_1                                                seq\n",
       "0     4.0   4.0   0.0  ACAATTTCACCATAAAATGTCGGCGTTGCCGAAAGAAATAAAATGA...\n",
       "1    19.0  13.0   6.0  ACGAGTTCCCCATAAAATTTGAGCGATGCCGAAAGAAATAAAAGTA...\n",
       "2     5.0   5.0   0.0  ACGAGTTCCCCATAAAATTTGAGCGATGCCGAAAGAAATAAAAGTA...\n",
       "3    11.0  11.0   0.0  ACGATTATCCCATAAAATGTGAACGATGCCGAAAGAAATAAAATTA...\n",
       "4     2.0   2.0   0.0  ACGATTTACCCGCAAAACGGGAGCGACGCCGCAAGAAACAAAATTA...\n",
       "..    ...   ...   ...                                                ...\n",
       "908   8.0   4.0   4.0  TTGATTTTCCCATTAAACATGCCCGATGCCGAAAGACATAAAATTA...\n",
       "909   4.0   4.0   0.0  TTGATTTTCCCATTAAACATGCCCGATGCCGAAAGACATAAAATTA...\n",
       "910   5.0   1.0   4.0  TTGTTTTTCCCAGAAAATGTAAGTCACGTCGACAGAAATAAAATTA...\n",
       "911   7.0   7.0   0.0  TTGTTTTTCCCAGAAAATGTAAGTCACGTCGACAGAAATAAAATTA...\n",
       "912   2.0   1.0   1.0  TTGTTTTTCCCAGAAAATGTAAGTCACGTCGACAGAAATAAAATTA...\n",
       "\n",
       "[913 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def main(\n",
    "    df,\n",
    "    modeltype='MAT',\n",
    "):\n",
    "    \n",
    "    # Determine dictionary\n",
    "    seq_cols = get_cols_from_df(df,'seqs')\n",
    "    \n",
    "    if not len(seq_cols)==1:\n",
    "        raise SortSeqError('Dataframe has multiple seq cols: %s'%str(seq_cols))\n",
    "    dicttype = colname_to_seqtype_dict[seq_cols[0]]\n",
    "\n",
    "    seq_dict, inv_dict = choose_dict(dicttype, modeltype=modeltype)\n",
    "\n",
    "    type_name_dict = {'dna':'seq','rna':'seq_rna','protein':'seq_pro'}\n",
    "    seq_col_name = type_name_dict[dicttype]\n",
    "    \n",
    "    par_seq_dict = {v:k for v,k in seq_dict.items() if k != (len(seq_dict)-1)}\n",
    "    \n",
    "    #drop any rows with ct = 0\n",
    "    df = df[df.loc[:,'ct'] != 0]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    #If there are sequences of different lengths, then print error but continue\n",
    "    if len(set(df[seq_col_name].apply(len))) > 1:\n",
    "         sys.stderr.write('Lengths of all sequences are not the same!')\n",
    "    return df\n",
    "\n",
    "main(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next two lines, we clip bases off the sequence, depending on the arguments given to the function. Then, the dataframe is reorganized into a common format.\n",
    "\n",
    "    #select target sequence region\n",
    "    df.loc[:,seq_col_name] = df.loc[:,seq_col_name].str.slice(start,end)\n",
    "    df = utils.collapse_further(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ct</th>\n",
       "      <th>ct_0</th>\n",
       "      <th>ct_1</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ACAATTTCACCATAAAATGTCGGCGTTGCCGAAAGAAATAAAATGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>ACGAGTTCCCCATAAAATTTGAGCGATGCCGAAAGAAATAAAAGTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ACGAGTTCCCCATAAAATTTGAGCGATGCCGAAAGAAATAAAAGTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ACGATTATCCCATAAAATGTGAACGATGCCGAAAGAAATAAAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ACGATTTACCCGCAAAACGGGAGCGACGCCGCAAGAAACAAAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>TTGATTTTCCCATTAAACATGCCCGATGCCGAAAGACATAAAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TTGATTTTCCCATTAAACATGCCCGATGCCGAAAGACATAAAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>TTGTTTTTCCCAGAAAATGTAAGTCACGTCGACAGAAATAAAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TTGTTTTTCCCAGAAAATGTAAGTCACGTCGACAGAAATAAAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TTGTTTTTCCCAGAAAATGTAAGTCACGTCGACAGAAATAAAATTA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>913 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ct  ct_0  ct_1                                                seq\n",
       "0     4.0   4.0   0.0  ACAATTTCACCATAAAATGTCGGCGTTGCCGAAAGAAATAAAATGA...\n",
       "1    19.0  13.0   6.0  ACGAGTTCCCCATAAAATTTGAGCGATGCCGAAAGAAATAAAAGTA...\n",
       "2     5.0   5.0   0.0  ACGAGTTCCCCATAAAATTTGAGCGATGCCGAAAGAAATAAAAGTA...\n",
       "3    11.0  11.0   0.0  ACGATTATCCCATAAAATGTGAACGATGCCGAAAGAAATAAAATTA...\n",
       "4     2.0   2.0   0.0  ACGATTTACCCGCAAAACGGGAGCGACGCCGCAAGAAACAAAATTA...\n",
       "..    ...   ...   ...                                                ...\n",
       "908   8.0   4.0   4.0  TTGATTTTCCCATTAAACATGCCCGATGCCGAAAGACATAAAATTA...\n",
       "909   4.0   4.0   0.0  TTGATTTTCCCATTAAACATGCCCGATGCCGAAAGACATAAAATTA...\n",
       "910   5.0   1.0   4.0  TTGTTTTTCCCAGAAAATGTAAGTCACGTCGACAGAAATAAAATTA...\n",
       "911   7.0   7.0   0.0  TTGTTTTTCCCAGAAAATGTAAGTCACGTCGACAGAAATAAAATTA...\n",
       "912   2.0   1.0   1.0  TTGTTTTTCCCAGAAAATGTAAGTCACGTCGACAGAAATAAAATTA...\n",
       "\n",
       "[913 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def collapse_further(df):\n",
    "    \"\"\"take clipped df and then collapse it further\"\"\"\n",
    "    # automatically pick the column name for the sequences\n",
    "    seq_col_name = [x for x in df.columns if \"seq\" in x][0]\n",
    "    output_df = df.groupby(seq_col_name).sum()\n",
    "    output_df = output_df.reset_index()\n",
    "    # now reorder columns so we have 'ct' first and 'seq' last\n",
    "    ct_columns = [x for x in df.columns if \"ct\" in x]\n",
    "    output_df = output_df[ct_columns + [seq_col_name]]\n",
    "    # The evaluated column will now be incorrect, so we should delete it.\n",
    "    try:\n",
    "        output_df = output_df.drop(\"val\", axis=1)\n",
    "    except:\n",
    "        pass\n",
    "    return output_df\n",
    "\n",
    "\n",
    "def main(\n",
    "    df,\n",
    "    modeltype='MAT',\n",
    "    start=0,\n",
    "    end=None\n",
    "):\n",
    "    \n",
    "    # Determine dictionary\n",
    "    seq_cols = get_cols_from_df(df,'seqs')\n",
    "    \n",
    "    if not len(seq_cols)==1:\n",
    "        raise SortSeqError('Dataframe has multiple seq cols: %s'%str(seq_cols))\n",
    "    dicttype = colname_to_seqtype_dict[seq_cols[0]]\n",
    "\n",
    "    seq_dict, inv_dict = choose_dict(dicttype, modeltype=modeltype)\n",
    "\n",
    "    type_name_dict = {'dna':'seq','rna':'seq_rna','protein':'seq_pro'}\n",
    "    seq_col_name = type_name_dict[dicttype]\n",
    "    \n",
    "    par_seq_dict = {v:k for v,k in seq_dict.items() if k != (len(seq_dict)-1)}\n",
    "    \n",
    "    #drop any rows with ct = 0\n",
    "    df = df[df.loc[:,'ct'] != 0]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    #If there are sequences of different lengths, then print error but continue\n",
    "    if len(set(df[seq_col_name].apply(len))) > 1:\n",
    "        sys.stderr.write('Lengths of all sequences are not the same!')\n",
    "            \n",
    "    #select target sequence region\n",
    "    df.loc[:,seq_col_name] = df.loc[:,seq_col_name].str.slice(start,end)\n",
    "    df = collapse_further(df)\n",
    "    return df\n",
    "\n",
    "main(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this did not change anything. But only because the dataframe is already prepared to be in the right format. In the next lines are only further formatting the data table.\n",
    "\n",
    "    col_headers = utils.get_column_headers(df)\n",
    "    #make sure all counts are ints\n",
    "    df[col_headers] = df[col_headers].astype(int)\n",
    "    #create vector of column names\n",
    "    val_cols = ['val_' + inv_dict[i] for i in range(len(seq_dict))]\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "    #Drop any sequences with incorrect length\n",
    "    if not end:\n",
    "        '''is no value for end of sequence was supplied, assume first seq is\n",
    "            correct length'''\n",
    "        seqL = len(df[seq_col_name][0]) - start\n",
    "    else:\n",
    "        seqL = end-start\n",
    "    df = df[df[seq_col_name].apply(len) == (seqL)]\n",
    "    df.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_headers(df,exptype=None):\n",
    "    col_headers = [name for name in df.columns if 'ct_' in name]              \n",
    "    return col_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ct</th>\n",
       "      <th>ct_0</th>\n",
       "      <th>ct_1</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>ACAATTTCACCATAAAATGTCGGCGTTGCCGAAAGAAATAAAATGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.0</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>ACGAGTTCCCCATAAAATTTGAGCGATGCCGAAAGAAATAAAAGTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>ACGAGTTCCCCATAAAATTTGAGCGATGCCGAAAGAAATAAAAGTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>ACGATTATCCCATAAAATGTGAACGATGCCGAAAGAAATAAAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>ACGATTTACCCGCAAAACGGGAGCGACGCCGCAAGAAACAAAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>TTGATTTTCCCATTAAACATGCCCGATGCCGAAAGACATAAAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>TTGATTTTCCCATTAAACATGCCCGATGCCGAAAGACATAAAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>TTGTTTTTCCCAGAAAATGTAAGTCACGTCGACAGAAATAAAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>TTGTTTTTCCCAGAAAATGTAAGTCACGTCGACAGAAATAAAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TTGTTTTTCCCAGAAAATGTAAGTCACGTCGACAGAAATAAAATTA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>913 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ct  ct_0  ct_1                                                seq\n",
       "0     4.0     4     0  ACAATTTCACCATAAAATGTCGGCGTTGCCGAAAGAAATAAAATGA...\n",
       "1    19.0    13     6  ACGAGTTCCCCATAAAATTTGAGCGATGCCGAAAGAAATAAAAGTA...\n",
       "2     5.0     5     0  ACGAGTTCCCCATAAAATTTGAGCGATGCCGAAAGAAATAAAAGTA...\n",
       "3    11.0    11     0  ACGATTATCCCATAAAATGTGAACGATGCCGAAAGAAATAAAATTA...\n",
       "4     2.0     2     0  ACGATTTACCCGCAAAACGGGAGCGACGCCGCAAGAAACAAAATTA...\n",
       "..    ...   ...   ...                                                ...\n",
       "908   8.0     4     4  TTGATTTTCCCATTAAACATGCCCGATGCCGAAAGACATAAAATTA...\n",
       "909   4.0     4     0  TTGATTTTCCCATTAAACATGCCCGATGCCGAAAGACATAAAATTA...\n",
       "910   5.0     1     4  TTGTTTTTCCCAGAAAATGTAAGTCACGTCGACAGAAATAAAATTA...\n",
       "911   7.0     7     0  TTGTTTTTCCCAGAAAATGTAAGTCACGTCGACAGAAATAAAATTA...\n",
       "912   2.0     1     1  TTGTTTTTCCCAGAAAATGTAAGTCACGTCGACAGAAATAAAATTA...\n",
       "\n",
       "[913 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def main(\n",
    "    df,\n",
    "    modeltype='MAT',\n",
    "    start=0,\n",
    "    end=None\n",
    "):\n",
    "    \n",
    "    # Determine dictionary\n",
    "    seq_cols = get_cols_from_df(df,'seqs')\n",
    "    \n",
    "    if not len(seq_cols)==1:\n",
    "        raise SortSeqError('Dataframe has multiple seq cols: %s'%str(seq_cols))\n",
    "    dicttype = colname_to_seqtype_dict[seq_cols[0]]\n",
    "\n",
    "    seq_dict, inv_dict = choose_dict(dicttype, modeltype=modeltype)\n",
    "\n",
    "    type_name_dict = {'dna':'seq','rna':'seq_rna','protein':'seq_pro'}\n",
    "    seq_col_name = type_name_dict[dicttype]\n",
    "    \n",
    "    par_seq_dict = {v:k for v,k in seq_dict.items() if k != (len(seq_dict)-1)}\n",
    "    \n",
    "    #drop any rows with ct = 0\n",
    "    df = df[df.loc[:,'ct'] != 0]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    #If there are sequences of different lengths, then print error but continue\n",
    "    if len(set(df[seq_col_name].apply(len))) > 1:\n",
    "        sys.stderr.write('Lengths of all sequences are not the same!')\n",
    "            \n",
    "    #select target sequence region\n",
    "    df.loc[:,seq_col_name] = df.loc[:,seq_col_name].str.slice(start,end)\n",
    "    df = collapse_further(df)\n",
    "    col_headers = get_column_headers(df)\n",
    "    #make sure all counts are ints\n",
    "    df[col_headers] = df[col_headers].astype(int)\n",
    "    #create vector of column names\n",
    "    val_cols = ['val_' + inv_dict[i] for i in range(len(seq_dict))]\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "    #Drop any sequences with incorrect length\n",
    "    if not end:\n",
    "        '''is no value for end of sequence was supplied, assume first seq is\n",
    "            correct length'''\n",
    "        seqL = len(df[seq_col_name][0]) - start\n",
    "    else:\n",
    "        seqL = end-start\n",
    "    df = df[df[seq_col_name].apply(len) == (seqL)]\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "main(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we understood all lines which format the data, we can start looking at the inference part of the code. For now, we start with the information maximization method. The first line there is:\n",
    "\n",
    "    seq_mat,wtrow = numerics.dataset2mutarray(df.copy(), modeltype)\n",
    "    \n",
    "As we look at this function, we will need to do a little detour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### => `dataset2mutarray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset2mutarray(dataset_df, modeltype, chunksize=1000, rowsforwtcalc=100):\n",
    "\n",
    "    # Determine the type of model and set seq2array function appropriately\n",
    "    if modeltype=='MAT':\n",
    "        seqs2array = mpathic.fast.seqs2array_for_matmodel\n",
    "    elif modeltype=='NBR':\n",
    "        seqs2array = mpathic.fast.seqs2array_for_nbrmodel\n",
    "    else:\n",
    "        raise SortSeqError('Unknown model type: %s'%modeltype)\n",
    "\n",
    "    # Determine seqtype, etc.\n",
    "    seqcol = qc.get_cols_from_df(dataset_df,'seqs')[0]\n",
    "    seqtype = qc.colname_to_seqtype_dict[seqcol]\n",
    "    wtcol = qc.seqtype_to_wtcolname_dict[seqtype]\n",
    "\n",
    "    # Compute the wt sequence\n",
    "    rowsforwtcalc = min(rowsforwtcalc,dataset_df.shape[0])\n",
    "    dataset_head_df = dataset_df.head(rowsforwtcalc)\n",
    "    mut_df = profile_mut(dataset_head_df)\n",
    "    wtseq = ''.join(list(mut_df[wtcol]))\n",
    "    wtrow = seqs2array([wtseq], seq_type=seqtype).ravel().astype(bool)\n",
    "    numfeatures = len(wtrow)\n",
    "\n",
    "    # Process dataframe in chunks\n",
    "    startrow = 0\n",
    "    endrow = startrow+chunksize-1\n",
    "    numrows = dataset_df.shape[0]\n",
    "\n",
    "    # Fill in mutarray (a lil matrix) chunk by chunk\n",
    "    mutarray_lil = lil_matrix((numrows,numfeatures),dtype=int)\n",
    "    matrix_filled = False\n",
    "    while not matrix_filled:\n",
    "\n",
    "        if startrow >= numrows:\n",
    "            matrix_filled = True\n",
    "            continue\n",
    "        elif endrow >= numrows:\n",
    "            endrow = numrows-1\n",
    "            matrix_filled = True\n",
    "\n",
    "        # Compute seqarray\n",
    "        seqlist = list(dataset_df[seqcol][startrow:(endrow+1)])\n",
    "        seqarray = seqs2array(seqlist, seq_type=seqtype)\n",
    "\n",
    "        # Remove wt entries\n",
    "        tmp = seqarray.copy()\n",
    "        tmp[:,wtrow] = 0\n",
    "\n",
    "        # Store results from this chunk\n",
    "        mutarray_lil[startrow:(endrow+1),:] = tmp\n",
    "\n",
    "        # Increment rows\n",
    "        startrow = endrow+1\n",
    "        endrow = startrow + chunksize - 1\n",
    "\n",
    "    # Convert to csr matrix\n",
    "    mutarray_csr = mutarray_lil.tocsr()\n",
    "\n",
    "    # Return vararray as well as binary representation of wt seq\n",
    "    return mutarray_csr, wtrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### => `mpathic.fast.seqs2array_for_matmodel`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part uses some code written C I think. So from here we kinda need to switch to Julia I think to proceed. At least there we won't need to use C or anything, and write everything in native Julia. So from here we just describe what the code is supposed to do instead of running it line by line.\n",
    "\n",
    "    def seqs2array_for_matmodel(list seq_list, str seq_type, bool safe=True):\n",
    "    \"\"\"\n",
    "    Converts a list of sequences (all of which must be the same length) to a numpy array to be used for matrix model evaluation\n",
    "    \"\"\"\n",
    "Just define some parameters\n",
    "\n",
    "    cdef np.ndarray[DTYPE_t, ndim=2] mat\n",
    "    cdef str c, seq\n",
    "    cdef int num_seqs, seq_length, num_chars, i, n, k\n",
    "    cdef dict c_to_i_dict\n",
    "\n",
    "Self explaining line\n",
    "\n",
    "    # Validate seq_type if in safe mode\n",
    "    if safe and (not seq_type in qc.seqtypes):\n",
    "        raise SortSeqError('Invalid seq_type: %s.'%seq_type)\n",
    "\n",
    "Just another dictionary which translates letters from a certain sequence type into integers\n",
    "\n",
    "    # Get character dictionary\n",
    "    c_to_i_dict = qc.char_to_mat_index_dicts[seq_type]\n",
    "    num_chars = len(c_to_i_dict)\n",
    "\n",
    "Initialize a matrix in which each sequence is translated into an array of 1's and 0's, with the ith to ith+alphabet_size positions being for the ith letter in the sequence, and having a 1 at the position in this subsequence depending on the dictionary.\n",
    "\n",
    "    # Initialize matrix\n",
    "    num_seqs = len(seq_list)\n",
    "    seq_length = len(seq_list[0])\n",
    "    mat = np.zeros([num_seqs,num_chars*seq_length], dtype=DTYPE)\n",
    "\n",
    "    # Fill matrix row by row\n",
    "    for n, seq in enumerate(seq_list):\n",
    "\n",
    "        # Validate sequence composition if in safe mode\n",
    "        if safe and qc.seqerr_re_dict[seq_type].search(seq):\n",
    "            raise SortSeqError(\\\n",
    "                'Invalid character found in %s sequence.'%seq_type)\n",
    "\n",
    "        # Validate sequence length if in safe mode\n",
    "        if safe and len(seq)!=seq_length:\n",
    "            raise SortSeqError('Sequences are not all the same length.')\n",
    "\n",
    "        # Fill in array\n",
    "        for i, c in enumerate(seq):\n",
    "            k = c_to_i_dict[c]\n",
    "            mat[n,num_chars*i+k] = 1\n",
    "    return mat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `dataset2mutarray`<="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going back to the function `dataset2mutarray` function. After computing this array, the next three lines are \n",
    "\n",
    "    # Determine seqtype, etc.\n",
    "    seqcol = qc.get_cols_from_df(dataset_df,'seqs')[0]\n",
    "    seqtype = qc.colname_to_seqtype_dict[seqcol]\n",
    "    wtcol = qc.seqtype_to_wtcolname_dict[seqtype]\n",
    "    \n",
    "where we already used the function in the first line and defined the dictionary in the second, leaving us only with defining the dictionary in the third line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqtype_to_wtcolname_dict = {\n",
    "    'dna':'wt',\n",
    "    'rna':'wt_rna',\n",
    "    'protein':'wt_pro'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next lines, we try to find the wild type sequence. First, we take a number of rows of the dataframe (first two lines), and then use this number of rows from the data frame. In the third row, we use the function `profile_mut`, which we will investigate below.\n",
    "\n",
    "    # Compute the wt sequence\n",
    "    rowsforwtcalc = min(rowsforwtcalc,dataset_df.shape[0])\n",
    "    dataset_head_df = dataset_df.head(rowsforwtcalc)\n",
    "    mut_df = profile_mut(dataset_head_df)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### => `profile_mut`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to validate the data set. In this pipeline however, this is done already multiple times, so we can ignore that for now. Next,     \n",
    "    \n",
    "    def main(dataset_df, bin=None, start=0, end=None, err=False):\n",
    "        \"\"\"\n",
    "        Computes the mutation rate (0.0 to 1.0) at each position. Mutation rate is defined as 1.0 minus the maximum character frequency at a position. Errors are estimated using bionomial uncertainty\n",
    "\n",
    "        Arguments:\n",
    "            dataset_df (pd.DataFrame): A dataframe containing a valid dataset.\n",
    "            bin (int): A bin number specifying which counts to use\n",
    "            start (int): An integer specifying the sequence start position\n",
    "            end (int): An integer specifying the sequence end position\n",
    "\n",
    "        Returns:\n",
    "            freq_df (pd.DataFrame): A dataframe containing results. \n",
    "        \"\"\"\n",
    "\n",
    "Validate data set. We don't have to look at the details here, since the data sets will be in the right format already.\n",
    "\n",
    "        # Validate dataset_df\n",
    "        qc.validate_dataset(dataset_df)\n",
    "\n",
    "Returns a dataframe, giving the counts of each letter at each position.\n",
    "\n",
    "        # Compute counts\n",
    "        counts_df = profile_ct.main(dataset_df, bin=bin, start=start, end=end)\n",
    "\n",
    "Get all count columns.\n",
    "\n",
    "        # Create columns for profile_freqs table\n",
    "        ct_cols = [c for c in counts_df.columns if qc.is_col_type(c,'ct_')]\n",
    "\n",
    "Create new data frame to store mutation rates and initiate with positions.\n",
    "\n",
    "        # Record positions in new dataframe\n",
    "        mut_df = counts_df[['pos']].copy()\n",
    "\n",
    "Look for base with highest count at each position, and assume it to be wild type base. Then divide by total number of counts, to get frequency of wild type base. Finally, subtract wild type base from 1.0, giving mutation rate. Store mutation rate in data frame.\n",
    "\n",
    "        # Compute mutation rate across counts\n",
    "        max_ct = counts_df[ct_cols].max(axis=1)\n",
    "        sum_ct = counts_df[ct_cols].sum(axis=1)\n",
    "        mut = 1.0 - (max_ct/sum_ct)\n",
    "        mut_df['mut'] = mut\n",
    "\n",
    "If wanted, compute error (which we see from the function call is not done).\n",
    "\n",
    "        # Computation of error rate is optional\n",
    "        if err:\n",
    "            mut_err = np.sqrt(mut*(1.0-mut)/sum_ct)\n",
    "            mut_df['mut_err'] = mut_err\n",
    "\n",
    "Figure out which alphabet is looked at. (I feel like we do this a lot and it could be done once and given as keyword argument, which is set as default to None, in which case it is looking the alphabet up.)\n",
    "\n",
    "        # Figure out which alphabet the cts dataframe specifies\n",
    "        alphabet = ''.join([c.split('_')[1] for c in ct_cols])\n",
    "        seqtype = qc.alphabet_to_seqtype_dict[alphabet]\n",
    "        wt_col = qc.seqtype_to_wtcolname_dict[seqtype]\n",
    "\n",
    "Store wild type base at each position.\n",
    "\n",
    "        # Compute WT base at each position\n",
    "        mut_df[wt_col] = 'X'\n",
    "        for col in ct_cols:\n",
    "            indices = (counts_df[col]==max_ct).values\n",
    "            mut_df.loc[indices,wt_col] = col.split('_')[1]\n",
    "\n",
    "Validate that the data frame has the right format.\n",
    "\n",
    "        # Validate as counts dataframe\n",
    "        mut_df = qc.validate_profile_mut(mut_df,fix=True)\n",
    "        return mut_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `dataset2mutarray` <="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we go back to the function `dataset2mutarray`. The next lines write the wild type sequence. Here\n",
    "\n",
    "    wtseq = ''.join(list(mut_df[wtcol]))\n",
    "  \n",
    "Use the function we read earlier to translate the wild type sequence to an array of `false` and `true`.\n",
    "\n",
    "    wtrow = seqs2array([wtseq], seq_type=seqtype).ravel().astype(bool)\n",
    "    numfeatures = len(wtrow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following section, we compute how many rows are processed at once. It seems like that is beneficial to processing the entire table at once. Maybe due smaller but repeated memory allocation (?).\n",
    "    \n",
    "    # Process dataframe in chunks\n",
    "    startrow = 0\n",
    "    endrow = startrow+chunksize-1\n",
    "    numrows = dataset_df.shape[0]\n",
    "    \n",
    "Then we create a scipy `lil_matrix`, which is a structure used to create sparse matrices incrementally.\n",
    "\n",
    "    # Fill in mutarray (a lil matrix) chunk by chunk\n",
    "    mutarray_lil = lil_matrix((numrows,numfeatures),dtype=int)\n",
    "    matrix_filled = False\n",
    "    \n",
    "In the following `while` loop, we compute the mutation array for chunks of the dataframe, until the entire matrix is filled. Since the wildtype is computed each time, it has to be removed in each iteration (this could be done better). \n",
    "\n",
    "    while not matrix_filled:\n",
    "\n",
    "        if startrow >= numrows:\n",
    "            matrix_filled = True\n",
    "            continue\n",
    "        elif endrow >= numrows:\n",
    "            endrow = numrows-1\n",
    "            matrix_filled = True\n",
    "\n",
    "        # Compute seqarray\n",
    "        seqlist = list(dataset_df[seqcol][startrow:(endrow+1)])\n",
    "        seqarray = seqs2array(seqlist, seq_type=seqtype)\n",
    "\n",
    "        # Remove wt entries\n",
    "        tmp = seqarray.copy()\n",
    "        tmp[:,wtrow] = 0\n",
    "\n",
    "        # Store results from this chunk\n",
    "        mutarray_lil[startrow:(endrow+1),:] = tmp\n",
    "\n",
    "        # Increment rows\n",
    "        startrow = endrow+1\n",
    "        endrow = startrow + chunksize - 1\n",
    "        \n",
    "Finally, the matrix is transformed to a compressed sparse row (csr) matrix, which improves the computation time.\n",
    "\n",
    "    # Convert to csr matrix\n",
    "    mutarray_csr = mutarray_lil.tocsr()\n",
    "\n",
    "    # Return vararray as well as binary representation of wt seq\n",
    "    return mutarray_csr, wtrow\n",
    "    \n",
    "So now we now how the dataframe is prepared for maximization of information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `learn_model.main` <="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we initialize the model. The model is set up differently depending on the model we are using. \n",
    "    \n",
    "    if initialize == 'rand':\n",
    "        if modeltype == 'MAT':\n",
    "            emat_0 = utils.RandEmat(len(df[seq_col_name][0]),len(seq_dict))\n",
    "        elif modeltype == 'NBR':\n",
    "            emat_0 = utils.RandEmat(len(df['seq'][0])-1,len(seq_dict))\n",
    "    elif initialize == 'LS':\n",
    "        emat_cols = ['val_' + inv_dict[i] for i in range(len(seq_dict))]\n",
    "        emat_0_df = main(df.copy(),lm='LS',modeltype=modeltype,alpha=alpha,start=0,end=None,verbose=verbose)\n",
    "        emat_0 = np.transpose(np.array(emat_0_df[emat_cols]))   \n",
    "         \n",
    "        \n",
    "We are only going to consider the line `emat_0 = utils.RandEmat(len(df[seq_col_name][0]),len(seq_dict))`, since this step initializes the energy matrix for our inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### => `utils.RandEmat(len(df[seq_col_name][0]),len(seq_dict))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function initializing the energy matrix seems to be quite simple. We simply draw each parameter from a the Standard Normal distribution.\n",
    "   \n",
    "    def RandEmat(L,Ldict):\n",
    "        '''Makes 4xL random emat'''\n",
    "        emat_0 = fix_matrix_gauge(sp.randn(Ldict,L))\n",
    "        return emat_0\n",
    "        \n",
    "Then, the values in each column are shifted such that the mean of each column is zero. Also, the matrix is rescaled such that the sum of variances of each column is equal to the length of the matrix. Here I wonder why that is important. Does that help with convergence?    \n",
    "        \n",
    "    def fix_matrix_gauge(emat):\n",
    "        \"\"\"Fix gauge of an energy matrix such that the minimum value\n",
    "        of each column is zero (columns correspond to positions), and\n",
    "        overall matrix norm is equal to 1.\"\"\"\n",
    "        # fix mean\n",
    "        for j in range(emat.shape[1]):\n",
    "            emat[:,j] = emat[:,j] -sp.mean(emat[:,j])\n",
    "        # fix sum of variances equal to length of matrix\n",
    "        svar = np.sum(np.var(emat,axis=0))\n",
    "        emat = sp.sqrt(emat.shape[1])*emat/sp.sqrt(svar)\n",
    "        return emat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `learn_model.main` <="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can finally get to the meat of the code, the actual inference! Now here we should see why the whole preparation is done the way it is and how we can learn from this to Stan this baby.\n",
    "\n",
    "    emat = MaximizeMI_memsaver(\n",
    "        seq_mat,\n",
    "        df.copy(),\n",
    "        emat_0,\n",
    "        wtrow,\n",
    "        db=db,\n",
    "        iteration=iteration,\n",
    "        burnin=burnin,\n",
    "        thin=thin,\n",
    "        runnum=runnum,\n",
    "        verbose=verbose\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### => `MaximizeMI_memsaver`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the function and go through it line by line\n",
    "    \n",
    "    def MaximizeMI_memsaver(\n",
    "            seq_mat,df,emat_0,wtrow,db=None,burnin=1000,iteration=30000,thin=10,\n",
    "            runnum=0,verbose=False):\n",
    "        '''Performs MCMC MI maximzation in the case where lm = memsaver'''    \n",
    "        '''\n",
    "        @pymc.stochastic(observed=True,dtype=sp.sparse.csr_matrix)\n",
    "        def sequences(value=seq_mat):\n",
    "            return 0\n",
    "        '''\n",
    "\n",
    "First we just count how many sequences we are looking at.\n",
    "\n",
    "        n_seqs = seq_mat.shape[0]\n",
    "        \n",
    "Next, we define a pymc variable, which is stochastic, but observed, meaning that it is fixed (data).\n",
    "        \n",
    "        @pymc.stochastic(observed=True,dtype=pd.DataFrame)\n",
    "        def pymcdf(value=df):\n",
    "            return 0\n",
    "            \n",
    "Next, we define another variable, which returns the exponent of the log likelihood, the number of sequences times the mutual information. Here we need to take a couple of detours.\n",
    "\n",
    "        @pymc.stochastic(dtype=float)\n",
    "        def emat(p=pymcdf,value=emat_0):         \n",
    "            p['val'] = numerics.eval_modelmatrix_on_mutarray(np.transpose(value),seq_mat,wtrow)                     \n",
    "            MI = EstimateMutualInfoforMImax.alt4(p.copy())  # New and improved\n",
    "            return n_seqs*MI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### =>`numerics.eval_modelmatrix_on_mutarray`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function starts by a bunch of error checking, to verify that the input data is of the right format.\n",
    "    \n",
    "    def eval_modelmatrix_on_mutarray(modelmatrix, mutarray, wtrow):\n",
    "\n",
    "        # Do error checking\n",
    "        if not isinstance(modelmatrix,np.ndarray):\n",
    "            raise SortSeqError('modelmatrix is not a np.ndarray')\n",
    "        if not isinstance(wtrow,np.ndarray):\n",
    "            raise SortSeqError('wtrow is not an np.ndarray')\n",
    "        if not isinstance(mutarray,csr.csr_matrix):\n",
    "            raise SortSeqErorr('mutarray is not a sparse csr_matrix')\n",
    "            raise SortSeqError('Unrecognized model type %s'%modeltype)\n",
    "        if len(wtrow.shape)!=1:\n",
    "            raise SortSeqError('wtrow is not 1-dimensional')\n",
    "        if len(modelmatrix.shape)!=2:\n",
    "            raise SortSeqError('modelmatrix is not 2-dimensional')\n",
    "        if wtrow.size!=modelmatrix.size:\n",
    "            raise SortSeqError('wtrow does not match modelmatrix')\n",
    "\n",
    "Here we flatten the array of the model matrix, and do a scalar product with the wildtype sequence. **This is way better than what I was doing, since scalar product should be much faster than evaluating the matrix the way I did.**\n",
    "\n",
    "        # Compute constant contribution to model prediciton\n",
    "        modelmatrix_vec = modelmatrix.ravel()\n",
    "        const_val = np.dot(wtrow,modelmatrix_vec)\n",
    "\n",
    "Here we do some reshaping to bring the wild type sequence into the format of the energy matrix.\n",
    "\n",
    "        # Prepare matrix for scanning mutarray\n",
    "        tmp_matrix = modelmatrix.copy()\n",
    "        indices = wtrow.reshape(modelmatrix.shape).astype(bool)\n",
    "        \n",
    "Now we evaluate the energy matrix for the wild type and get its energy values. Then the values in the matrix are subtracted by the wild type energy.       \n",
    "        \n",
    "        wt_matrix_vals = tmp_matrix[indices]\n",
    "        tmp_matrix -= wt_matrix_vals[:,np.newaxis]\n",
    "        \n",
    "Now we can evaluate the matrix for the sequences and compute the final energy values by adding the wild type energies.\n",
    "        \n",
    "        modelmatrix_for_mutarray = csr_matrix(np.matrix(tmp_matrix.ravel()).T)\n",
    "\n",
    "        # Compute values\n",
    "        mutarray_vals = mutarray*modelmatrix_for_mutarray\n",
    "        vals = const_val + mutarray_vals.toarray().ravel()\n",
    "        return vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `MaximizeMI_memsaver` <="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### =>`EstimateMutualInfoforMImax.alt4`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now having the energies in hand, we need to perform the KDE.    \n",
    "    \n",
    "    def alt4(df, coarse_graining_level = 0.01):\n",
    "        '''\n",
    "        MI ESTIMATOR EDITED BY JBK \n",
    "        Used when lm=memsaver \n",
    "        REQUIRES TESTING AND PROFILING.\n",
    "        '''\n",
    "        \n",
    "First initiate the number if discrete energies for which we evaluate the KDE and how many distinct sequences, and therefore observed binding energies have. We also count how many different 'batches' there are in the data set, i.e., DNA and cDNA in our case.        \n",
    "\n",
    "        n_groups=500\n",
    "        n_seqs = len(df.index)\n",
    "        binheaders = utils.get_column_headers(df)\n",
    "        n_batches = len(binheaders)\n",
    "        cts_grouped = sp.zeros([n_groups,n_batches])\n",
    "        group_num = 0\n",
    "        frac_empty = 1.0\n",
    "\n",
    "        #copy dataframe\n",
    "        tmp_df = df.copy(binheaders+['val'])\n",
    "\n",
    "Here we can coarse grain the observed binding energies, to reduce the space and speed up computations.\n",
    "\n",
    "        # Speed computation by coarse-graining model predictions\n",
    "        if coarse_graining_level:\n",
    "            assert type(coarse_graining_level)==float\n",
    "            assert coarse_graining_level > 0\n",
    "            vals = tmp_df['val'].values\n",
    "            scale = np.std(vals)\n",
    "            coarse_vals = np.floor((vals/scale)/coarse_graining_level)\n",
    "            tmp_df['val'] = coarse_vals\n",
    "            grouped = tmp_df.groupby('val')\n",
    "            grouped_tmp_df = grouped.aggregate(np.sum)\n",
    "            grouped_tmp_df.sort_index(inplace=True)\n",
    "        else:\n",
    "            grouped_tmp_df = tmp_df\n",
    "            grouped_tmp_df.sort_values(by='val',inplace=True)\n",
    "        # Get ct_xxx columns\n",
    "        \n",
    "Extract the columns for counts of DNA and cDNA, and then compute the total number of counts for each. \n",
    "        \n",
    "        ct_df = grouped_tmp_df[binheaders].astype(float)\n",
    "        cts_per_group = ct_df.sum(axis=0).sum()/n_groups\n",
    "        # Histogram counts in groups. This is a bit tricky\n",
    "        group_vec = np.zeros(n_batches)\n",
    "        \n",
    "Iterate through every row of the data frame.\n",
    "\n",
    "        for i,row in ct_df.iterrows():\n",
    "        \n",
    "Compute the fraction of DNA and cDNA counts\n",
    "\n",
    "            row_ct_tot = row.sum()\n",
    "            row_ct_vec = row.values\n",
    "            row_frac_vec = row_ct_vec/row_ct_tot \n",
    "\n",
    "            while row_ct_tot >= cts_per_group*frac_empty:\n",
    "                group_vec = group_vec + row_frac_vec*(cts_per_group*frac_empty)\n",
    "                row_ct_tot -= cts_per_group*frac_empty\n",
    "\n",
    "                # Only do once per group_num\n",
    "                cts_grouped[group_num,:] = group_vec.copy() \n",
    "                # Reset for new group_num\n",
    "                group_num += 1\n",
    "                frac_empty = 1.0\n",
    "                group_vec[:] = 0.0\n",
    "            group_vec += row_frac_vec*row_ct_tot\n",
    "\n",
    "            frac_empty -= row_ct_tot/cts_per_group\n",
    "        if group_num == n_groups-1:\n",
    "            cts_grouped[group_num,:] = group_vec.copy()\n",
    "        elif group_num == n_groups:\n",
    "            pass\n",
    "        else:\n",
    "            raise TypeError(\\\n",
    "                'group_num=%d does not match n_groups=%s'%(group_num,n_groups))\n",
    "        # Smooth empirical distribution with gaussian KDE\n",
    "        f_reg = scipy.ndimage.gaussian_filter1d(cts_grouped,0.04*n_groups,axis=0)\n",
    "\n",
    "At this point we simply calculate the mutual information for the smoothed probability distribution.\n",
    "\n",
    "        # Return mutual information\n",
    "        return info.mutualinfo(f_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    if db:\n",
    "            dbname = db + '_' + str(runnum) + '.sql'\n",
    "            M = pymc.MCMC([pymcdf,emat],db='sqlite',dbname=dbname)\n",
    "        else:\n",
    "            M = pymc.MCMC([pymcdf,emat])\n",
    "        M.use_step_method(stepper.GaugePreservingStepper,emat)\n",
    "\n",
    "        if not verbose:\n",
    "            M.sample = shutthefuckup(M.sample)\n",
    "\n",
    "        M.sample(iteration,thin=thin)\n",
    "        emat_mean = np.mean(M.trace('emat')[burnin:],axis=0)\n",
    "        return emat_mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
